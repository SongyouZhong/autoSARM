# autoSARM 核心代码流程详解

**文档创建日期**: 2025年11月23日  
**分析文件**: `create_sarm.py`, `create_tree.py`  
**项目用途**: 药物化学中的结构-活性关系（SAR）分析与可视化

---

## 目录

1. [项目概述](#项目概述)
2. [create_sarm.py 详细流程](#create_sarmpy-详细流程)
3. [create_tree.py 详细流程](#create_treepy-详细流程)
4. [数据流转关系](#数据流转关系)
5. [核心算法说明](#核心算法说明)
6. [工具函数说明](#工具函数说明)

---

## 项目概述

### 整体架构

```
输入数据 (CSV with SMILES)
        ↓
create_sarm.py (片段化 + SAR表生成)
        ↓
SAR_Tables/ (中间数据)
        ↓
create_tree.py (树结构构建 + 可视化)
        ↓
输出结果 (PDF树图 + PNG图片)
```

### 核心功能

1. **create_sarm.py**: 分子片段化与SAR表格创建
   - 将完整分子切割成片段
   - 统计片段出现频率
   - 生成左、右、组合SAR表

2. **create_tree.py**: SAR树结构构建与可视化
   - 基于片段关系构建层次树
   - 突出显示符合活性条件的化合物
   - 生成可视化的SAR树图

---

## create_sarm.py 详细流程

### 1. 主函数入口 (main)

#### 1.1 参数解析与初始化
```python
def main(args):
    act_csv_file = args.csvFile      # 输入CSV文件路径
    value_cols = args.column         # 活性值列名列表
    log = args.log                   # 是否对活性值取对数
```

**处理内容**:
- 读取用户提供的CSV文件
- 确定要分析的活性值列（可多列同时分析）
- 设置是否对活性值进行对数转换

---

#### 1.2 数据预处理阶段

##### 步骤1: 加载数据
```python
dfAcat = pd.read_csv(act_csv_file)
dfAcat = float_row(dfAcat, cols=value_cols)
```

**功能**: 
- 读取CSV文件到DataFrame
- 将活性值列转换为浮点数类型
- 清理非数值数据

##### 步骤2: 对数转换（可选）
```python
for icol in value_cols:
    dfAcat[icol] = dfAcat[icol].apply(lambda x: math.log(x) if log else x)
```

**目的**: 
- 药物活性数据（如IC50）通常跨越多个数量级
- 对数转换使数据分布更均匀，便于统计分析

##### 步骤3: 验证与去重
```python
df_sele = df_valid(dfAcat, row_smi='smiles')  # 验证SMILES有效性

if 'Cano_SMILES' not in df_sele.columns:
    df_sele['Cano_SMILES'] = df_sele['smiles'].parallel_apply(canonic_smiles)
    
df_sele = df_sele.drop_duplicates(subset=['Cano_SMILES'])
```

**处理**:
- `df_valid()`: 验证SMILES字符串是否可被RDKit解析
- `canonic_smiles()`: 将SMILES标准化（消除同分异构体的不同写法）
- 去重: 基于标准化SMILES去除重复化合物

---

#### 1.3 分子类型选择

##### 模式1: Scaffold（骨架）模式
```python
if args.type == 'scaffold':
    df_sele['Scaffold'] = [MurckoScaffoldSmiles(ismi) for ismi in df_sele["Cano_SMILES"]]
    act_CPDs = df_sele['Scaffold']
    smi_col = 'Scaffold'
```

**Murcko骨架**:
- 提取分子的核心环系统
- 去除侧链，仅保留主要骨架
- 用于基于核心结构的SAR分析

**示例**:
```
原始分子: Cc1ccc(S(=O)(=O)NCCOC2CCC(CN3CCC(c4ccccc4)CC3)CC2)cc1
骨架:     c1ccc(S(=O)(=O)NCCOC2CCCCC2)cc1
```

##### 模式2: SMILES（完整分子）模式
```python
if args.type == 'smiles':
    act_CPDs = df_sele['Cano_SMILES']
    smi_col = 'Cano_SMILES'
```

**用途**: 基于完整分子结构的SAR分析

---

### 2. 分子片段化阶段

#### 2.1 两轮切割策略
```python
df_round1, df_round2 = fragmentize(
    act_CPDs, 
    n_jobs=args.n_jobs, 
    drop_duplicate=False, 
    pos_args={'RR':True, 'nRnR':True}
)
```

**fragmentize() 函数原理**:

##### Round 1: 单键切割
- **目标**: 在单键处切断分子
- **位置参数**:
  - `RR=True`: 切割连接两个环的键（Ring-Ring）
  - `nRnR=True`: 切割连接环与非环的键（nonRing-Ring）

**输出格式**:
```
原始分子: R1-Core-R2
切割后:   *-Core-* (核心片段，两端带*占位符)
         R1-*      (左侧R基团)
         *-R2      (右侧R基团)
```

##### Round 2: 二次切割
- 对Round 1的片段再次切割
- 生成更小的子片段
- 用于构建更深层的SAR树

**数据结构示例**:
```python
df_round1:
   Key                    SMILES              Count
0  *c1ccc(S(*)(=O)=O)cc1C  compound1,compound2  45
1  *CN1CCC(*)CC1           compound3,compound4  38

df_round2:
   Key                    SMILES              Parent_Key
0  *c1ccccc1              compound1           *c1ccc(S(*)(=O)=O)cc1C
1  *S(*)(=O)=O            compound1           *c1ccc(S(*)(=O)=O)cc1C
```

---

### 3. SAR表创建阶段

#### 3.1 create_SARM() 核心函数
```python
df_table_info_left, df_table_info_right, df_table_info_combine = create_SARM(
    df_round1,                    # Round 1片段数据
    df_round2,                    # Round 2片段数据
    df_sele,                      # 原始化合物数据
    save_folder=args.save_folder, # 输出目录
    smi_col=smi_col,             # SMILES列名
    value_col=value_cols,        # 活性值列名
    minimum_count_site1=args.minimumSite1,  # 左侧最小片段频次
    minimum_count_site2=args.minimumSite2,  # 右侧最小片段频次
    csv2excel=args.csv2excel,    # 是否转为Excel
    cal_table_stats=True,        # 是否计算统计值
    n_jobs=args.n_jobs          # 并行核心数
)
```

#### 3.2 输出文件结构

##### A. Left_Table_info.csv (左侧片段表)
```csv
Table_id,Root_Title,Root_SMILES,L_SMILES,Items_count,IC50_mean,IC50_std
100,Table_100,*c1ccc(S(*)(=O)=O)cc1C,*CCOC,12,1.5,0.8
```

**字段说明**:
- `Table_id`: 表格唯一ID
- `Root_SMILES`: 核心片段（带两个*）
- `L_SMILES`: 左侧R基团
- `Items_count`: 该组合出现的化合物数量
- `IC50_mean/std`: 活性值统计

##### B. Right_Table_info.csv (右侧片段表)
类似左表，但分析右侧R基团

##### C. Combine_Table_info.csv (组合表)
```csv
Table_id,Root_Title,Root_SMILES,SMILES,L_Table_id,R_Table_id,L_SMILES,R_SMILES,Items_count
100,Table_100_combine,*c1ccc(S(*)(=O)=O)cc1C,L100_R203_smiles,100,203,*CCOC,*c1ccccc1,5
```

**组合逻辑**:
- 将同一核心的不同左、右片段组合
- 记录每个组合对应的化合物数量
- 统计活性值的平均值、标准差等

#### 3.3 频次过滤
```python
minimum_count_site1 = 3  # 左侧片段至少出现3次
minimum_count_site2 = 3  # 右侧片段至少出现3次
```

**目的**: 
- 过滤掉稀有片段，避免统计不显著
- 确保SAR分析的可靠性

---

### 4. 输出文件组织

```
SAR_Tables/
├── Left_Table_info.csv        # 左侧片段统计
├── Right_Table_info.csv       # 右侧片段统计
├── Combine_Table_info.csv     # 组合片段统计
├── Frag_round1_count.csv      # Round 1片段计数
├── Frag_round2_count.csv      # Round 2片段计数
├── root_info.csv              # 核心片段信息
├── Left_Table/
│   ├── Table_100_left.csv     # 各个核心的左侧详细数据
│   └── ...
├── Right_Table/
│   ├── Table_100_right.csv    # 各个核心的右侧详细数据
│   └── ...
└── Combine_Table/
    ├── Table_100_combine.csv  # 各个核心的组合详细数据
    └── ...
```

---

## create_tree.py 详细流程

### 1. 初始化与参数解析

#### 1.1 核心参数
```python
def main(args):
    fragment_core = args.fragment_core     # 片段核心SMILES（带*）
    rootTitle = args.rootTitle             # 表格标题（如Table_100_combine）
    workFolder = args.workFolder           # 工作目录
    highlightDict = eval(args.highlightDict)  # 高亮条件字典
    max_level = args.maxLevel              # 树的最大层级
    treeContent = eval(args.treeContent)   # 树的内容类型
```

**参数示例**:
```bash
--fragment_core "*c1ccc(S(*)(=O)=O)cc1C"
--rootTitle "Table_100_combine"
--maxLevel 5
--treeContent "['double-cut']"
--highlightDict "[{'col':'IC50_uM', 'type':'mean', 'relation':'<', 'value':1.0}]"
```

#### 1.2 高亮条件解析
```python
highlightDict = [
    {
        'col': 'IC50_uM',      # 活性列名
        'type': 'mean',        # 统计类型：mean/median/std
        'relation': '<',       # 比较关系：</>/=
        'value': 1.0          # 阈值
    }
]
```

**含义**: 高亮平均IC50 < 1.0 µM的化合物（高活性）

---

### 2. 数据加载阶段

#### 2.1 加载片段表
```python
dfList = []

if 'double-cut' in treeContent:
    df_tmp = pd.read_csv(f"{workFolder}/SAR_Tables/Combine_Table_info.csv")
    # 兼容性处理：支持Key2和SMILES两种列名
    if "Key2" in df_tmp.columns:
        df_tmp["SMILES"] = df_tmp["Key2"]
    elif "SMILES" not in df_tmp.columns:
        raise ValueError("Must have 'Key2' or 'SMILES' column")
    dfList.append(df_tmp)

if 'single-cut' in treeContent:
    df_tmp = pd.read_csv(f"{workFolder}/SAR_Tables/singleCut_Table_info.csv")
    # 同样的兼容性处理
    dfList.append(df_tmp)

if 'whole-compound' in treeContent:
    df_tmp = pd.read_csv(f"{workFolder}/input.csv")
    df_tmp["SMILES"] = df_tmp["smiles"].parallel_apply(canonic_smiles)
    df_tmp["Items_count"] = 1
    dfList.append(df_tmp)

df_table = pd.concat(dfList)  # 合并所有表
```

**树内容类型**:
- `double-cut`: 使用二次切割的组合表（最常用）
- `single-cut`: 仅使用单次切割
- `whole-compound`: 包含完整化合物

#### 2.2 加载活性数据
```python
df_act = pd.read_csv(f"{workFolder}/input.csv")
df_act = float_row(df_act, cols=actCols, dropna=False)

if 'SMILES' not in df_act.columns and 'smiles' in df_act.columns:
    df_act['SMILES'] = df_act['smiles']
    
df_act['Cano_SMILES'] = df_act['SMILES'].parallel_apply(canonic_smiles)
df_act = df_act.dropna(subset=['Cano_SMILES'])
```

**数据准备**:
- 标准化活性值列为浮点数
- 标准化SMILES格式
- 去除无效数据

---

### 3. 树结构构建阶段

#### 3.1 片段匹配
```python
df_table['Matched'] = df_table.parallel_apply(
    lambda x: match_frag(x['SMILES'], ismarts=fragment_core), 
    axis=1
)
df_table = df_table[df_table['Matched'] == 1]
```

**match_frag() 功能**:
- 检查片段是否包含指定的核心结构
- 使用SMARTS模式匹配
- 过滤出所有匹配的片段

**示例**:
```
fragment_core = "*c1ccc(S(*)(=O)=O)cc1C"

匹配的片段:
✓ *NS(=O)(=O)c1ccc(*)c(C)c1
✓ *CNS(=O)(=O)c1ccc(*)c(C)c1
✗ *c1ccccc1  (不匹配)
```

#### 3.2 父子关系构建

##### 步骤1: 查找所有片段的子节点
```python
SMILESnoDummy = df_table["SMILES"].to_list()
children_dict = find_children(SMILESnoDummy)
```

**find_children() 原理**:
- 对每个片段，找出所有可以从它衍生的子片段
- 子片段 = 在父片段基础上进一步替换或切割

**示例**:
```python
parent: *c1ccc(S(*)(=O)=O)cc1C
children: [
    *NS(=O)(=O)c1ccc(*)c(C)c1,    # 切割苯环与磺酰胺
    *c1ccc(S(=O)(=O)N*)cc1C,      # 切割磺酰胺与R基团
]
```

##### 步骤2: 查找所有片段的父节点
```python
parent_dict = find_parents(SMILESnoDummy)
```

**find_parents() 原理**:
- 与find_children相反
- 找出可以衍生出当前片段的所有父片段

#### 3.3 构建树数据结构

##### Node类定义
```python
class node():
    def __init__(self, smi):
        self.root = True          # 是否为根节点
        self.SMILES = smi        # 片段SMILES
        self.children = []       # 子节点列表
        self.parents = []        # 父节点列表
    
    def add_child(self, node):
        node.root = False
        self.children.append(node)
```

##### 递归构建算法
```python
roots = [fragment_core]  # 从用户指定的核心开始
tree_list = []

for itree, ismi in enumerate(roots):
    inode = node(ismi)  # 创建根节点
    next_level_inodes = [inode]
    
    # 广度优先搜索（BFS）构建树
    while len(next_level_inodes) > 0:
        for jnode in next_level_inodes:
            children_smis = children_dict[jnode.SMILES]
            
            if len(children_smis) > 0:
                for ichild_smi in children_smis:
                    # 验证是否为真正的子节点（非跳跃关系）
                    if real_sonNode(ichild_smi, children_smis, parent_dict):
                        jnode.add_child(node(ichild_smi))
        
        # 移动到下一层
        tmp_next_level_inodes = []
        for jnode in next_level_inodes:
            tmp_next_level_inodes.extend(jnode.children)
        next_level_inodes = tmp_next_level_inodes
    
    tree_list.append(inode)
```

**构建逻辑**:
1. 从根节点（fragment_core）开始
2. 使用BFS逐层展开
3. 为每个节点添加所有直接子节点
4. 过滤掉非直接子节点（避免跳层）
5. 重复直到没有更多子节点

**树结构示例**:
```
Level 0: *c1ccc(S(*)(=O)=O)cc1C
         ├── Level 1: *NS(=O)(=O)c1ccc(*)c(C)c1
         │   ├── Level 2: *CNS(=O)(=O)c1ccc(*)c(C)c1
         │   │   └── Level 3: *CCNS(=O)(=O)c1ccc(*)c(C)c1
         │   └── Level 2: *c1ccc(S(=O)(=O)N*)cc1C
         └── Level 1: *Nc1ccc(S(*)(=O)=O)cc1C
```

---

### 4. 树可视化阶段

#### 4.1 Graphviz初始化
```python
d = graphviz.Digraph(filename=f'{rootTitle}')
d.node_attr["shape"] = "plaintext"
d.node_attr["fixedsize"] = 'true'
d.node_attr["height"] = '1'
d.node_attr["width"] = '1'

# 字体设置
d.attr(fontsize='20')
d.node_attr.update(fontsize='18', fontname='SimHei')
d.edge_attr.update(fontsize='18')
```

#### 4.2 逐层绘制

##### 层级遍历
```python
for ilevel_idx, ilevel_smiles in enumerate(itree_smiles):
    if ilevel_idx > max_level:
        break
    
    with d.subgraph() as s:
        s.attr(rank='same')  # 同层节点水平对齐
        
        for inode, cpds_node in enumerate(ilevel_smiles):
            # 为每个节点生成图片
            for icpd in cpds_node:
                img_path = f"Images/L{ilevel_idx}_{count}.png"
                show_cpd(
                    [img_path, icpd],
                    df_table=df_table,
                    df_act=df_act,
                    actCols=actCols,
                    highlightDictList=highlightDict
                )
```

##### show_cpd() 节点绘制函数
```python
def show_cpd(icpd_countList, df_table, df_act, actCols, highlightDictList):
    """
    功能：绘制单个节点的分子结构和活性信息
    
    参数：
    - icpd_countList: [图片路径, 片段SMILES]
    - df_table: 片段表
    - df_act: 活性数据表
    - actCols: 活性列名列表
    - highlightDictList: 高亮条件
    
    输出：PNG图片文件
    """
```

**绘制内容**:
1. **分子结构图**: 使用RDKit绘制片段结构
2. **统计信息**: 
   - 化合物数量（Items_count）
   - 活性值统计（mean, std, median）
3. **高亮显示**: 
   - 满足highlightDict条件的节点用特殊颜色标记
   - 例如：IC50 < 1.0的节点显示为绿色

**高亮逻辑**:
```python
for highlight in highlightDictList:
    col = highlight['col']         # IC50_uM
    stat_type = highlight['type']  # mean
    relation = highlight['relation']  # <
    threshold = highlight['value'] # 1.0
    
    # 从df_act中匹配该片段的化合物
    matched_cpds = df_act[df_act['Cano_SMILES'].isin(fragment_matched_smiles)]
    
    # 计算统计值
    if stat_type == 'mean':
        stat_value = matched_cpds[col].mean()
    elif stat_type == 'median':
        stat_value = matched_cpds[col].median()
    
    # 判断是否满足条件
    if relation == '<' and stat_value < threshold:
        highlight_node = True
    # ... 其他关系判断
```

#### 4.3 边的连接
```python
if ilevel_idx > 0:
    # 连接父节点和子节点
    d.edge(
        f'L{ilevel_idx-1}_{inode}',  # 父节点ID
        node_label,                   # 子节点ID
        penwidth='0.2',              # 线宽
        arrowsize='0.2'              # 箭头大小
    )
```

#### 4.4 去重处理
```python
levelNodeDict = {}  # 记录本层已显示的片段

if cpdSmi not in levelNodeDict.keys():
    # 首次出现，正常显示
    node_label = f"L{ilevel_idx}_{count}"
    s.node(node_label, image=img_icpd[0])
    levelNodeDict[cpdSmi] = node_label
else:
    # 重复出现，创建虚拟节点维持布局
    node_label = f"L{ilevel_idx}_{count}"
    s.node(node_label)  # 空节点
    levelDummyNodeList.append(node_label)
    
    # 使用之前的节点进行连接
    node_label = levelNodeDict[cpdSmi]
```

**目的**: 
- 同一片段可能通过不同路径到达
- 避免重复显示相同片段
- 保持树的布局整洁

#### 4.5 输出生成
```python
d.render(view=False)  # 生成PDF和源文件
```

**输出文件**:
- `Table_100_combine.pdf`: 最终的树状图PDF
- `Table_100_combine.gv`: Graphviz源文件
- `Images/L{level}_{id}.png`: 各节点的分子结构图

---

## 数据流转关系

### 完整数据流

```
┌─────────────────────────────────────────────────────────────┐
│ 阶段1: 输入数据准备                                          │
├─────────────────────────────────────────────────────────────┤
│ input.csv (原始化合物数据)                                   │
│   - smiles: 分子SMILES字符串                                 │
│   - IC50_uM, TLR7IC50, etc: 活性值                          │
└───────────────────┬─────────────────────────────────────────┘
                    ↓
┌─────────────────────────────────────────────────────────────┐
│ 阶段2: create_sarm.py - 片段化                              │
├─────────────────────────────────────────────────────────────┤
│ 1. 数据验证与标准化                                          │
│    - SMILES有效性检查                                        │
│    - 标准化SMILES (Cano_SMILES)                             │
│    - 活性值转换（可选对数）                                   │
│                                                              │
│ 2. 分子切割 (fragmentize)                                    │
│    Round 1: 单键切割                                         │
│      R1-Core-R2 → [*-Core-*, R1-*, *-R2]                   │
│    Round 2: 二次切割                                         │
│      对Round 1片段再切割                                      │
│                                                              │
│ 3. 统计与过滤                                                │
│    - 计算片段出现频次                                         │
│    - 过滤低频片段 (minimum_count)                            │
│                                                              │
│ 4. SAR表生成 (create_SARM)                                  │
│    - 左表: 固定核心，变化左侧R基                              │
│    - 右表: 固定核心，变化右侧R基                              │
│    - 组合表: 左右组合                                         │
│    - 统计活性值: mean, std, median, min, max                │
└───────────────────┬─────────────────────────────────────────┘
                    ↓
┌─────────────────────────────────────────────────────────────┐
│ 阶段3: 中间数据存储 (SAR_Tables/)                           │
├─────────────────────────────────────────────────────────────┤
│ - Combine_Table_info.csv: 所有核心的组合表索引               │
│ - Left_Table_info.csv: 左侧片段索引                          │
│ - Right_Table_info.csv: 右侧片段索引                         │
│ - Frag_round1_count.csv: Round 1片段统计                    │
│ - Frag_round2_count.csv: Round 2片段统计                    │
│ - root_info.csv: 核心片段信息                                │
│ - Combine_Table/Table_{id}_combine.csv: 详细组合数据         │
│ - Left_Table/Table_{id}_left.csv: 详细左侧数据               │
│ - Right_Table/Table_{id}_right.csv: 详细右侧数据             │
└───────────────────┬─────────────────────────────────────────┘
                    ↓
┌─────────────────────────────────────────────────────────────┐
│ 阶段4: create_tree.py - 树构建                              │
├─────────────────────────────────────────────────────────────┤
│ 1. 数据加载                                                  │
│    - 读取SAR_Tables中的片段表                                │
│    - 读取input.csv中的活性数据                               │
│    - 匹配fragment_core指定的核心片段                          │
│                                                              │
│ 2. 父子关系分析                                              │
│    - find_children(): 找出每个片段的子片段                    │
│    - find_parents(): 找出每个片段的父片段                     │
│    - 构建片段层次关系字典                                     │
│                                                              │
│ 3. 树结构构建                                                │
│    - 使用BFS从根节点展开                                      │
│    - 创建node对象表示每个片段                                 │
│    - 递归添加子节点，最大深度max_level                        │
│                                                              │
│ 4. 活性信息关联                                              │
│    - 匹配每个片段对应的化合物                                 │
│    - 计算活性统计值（mean, std, median）                      │
│    - 根据highlightDict判断是否高亮                           │
│                                                              │
│ 5. 可视化生成                                                │
│    - 使用RDKit绘制分子结构                                    │
│    - 使用Graphviz构建树图布局                                │
│    - 生成PNG节点图片                                          │
│    - 渲染最终PDF                                             │
└───────────────────┬─────────────────────────────────────────┘
                    ↓
┌─────────────────────────────────────────────────────────────┐
│ 阶段5: 输出结果 (SAR_Results/Trees/)                        │
├─────────────────────────────────────────────────────────────┤
│ FragTree_{rootTitle}/                                       │
│   ├── {rootTitle}.pdf: 完整SAR树可视化图                     │
│   ├── {rootTitle}.gv: Graphviz源文件                         │
│   ├── Combine_Table_info_Tree_{rootTitle}.txt: 文本树结构    │
│   └── Images/                                                │
│       ├── L0_0.png: 第0层第0个节点                           │
│       ├── L1_0.png: 第1层第0个节点                           │
│       └── ...                                                │
└─────────────────────────────────────────────────────────────┘
```

---

## 核心算法说明

### 1. 片段化算法 (fragmentize)

#### 算法目标
将完整分子在特定位置切断，生成带占位符(*)的片段

#### 切割规则

##### 规则1: Ring-Ring (RR)
```
切割位置: 连接两个环的单键

示例:
原始: c1ccccc1-CCc2ccccc2
切割: c1ccccc1* + *CCc2ccccc2
```

##### 规则2: nonRing-Ring (nRnR)
```
切割位置: 连接环与非环原子的单键

示例:
原始: c1ccccc1-CCO
切割: c1ccccc1* + *CCO
```

##### 规则3: 保留多个切点
```
对称切割: 在分子两端切断

示例:
原始: R1-Core-R2
切割: 
  - *-Core-*  (核心，两端都是*)
  - R1-*      (左基团)
  - *-R2      (右基团)
```

#### 实现伪代码
```python
def fragmentize(smiles_list):
    round1_fragments = []
    
    for smi in smiles_list:
        mol = Chem.MolFromSmiles(smi)
        bonds = mol.GetBonds()
        
        for bond in bonds:
            # 检查是否为单键
            if bond.GetBondType() != Chem.BondType.SINGLE:
                continue
            
            atom1 = bond.GetBeginAtom()
            atom2 = bond.GetEndAtom()
            
            # 检查RR或nRnR条件
            if (atom1.IsInRing() and atom2.IsInRing()) or \
               (atom1.IsInRing() != atom2.IsInRing()):
                # 在此键处切断
                frag1, frag2 = cut_bond(mol, bond)
                round1_fragments.append([frag1, frag2])
    
    # Round 2: 对Round 1片段再切割
    round2_fragments = fragmentize(round1_fragments)
    
    return round1_fragments, round2_fragments
```

---

### 2. 父子关系算法

#### find_children() 实现逻辑

**目标**: 给定片段A，找出所有可以从A衍生的片段B

**判定条件**:
```python
def is_child(parent_smi, child_smi):
    """
    判定规则:
    1. child的原子数 ≤ parent的原子数
    2. child的*占位符数量 ≥ parent的*占位符数量
    3. child可以通过替换parent中的某个基团得到
    """
    
    parent_mol = Chem.MolFromSmarts(parent_smi)
    child_mol = Chem.MolFromSmarts(child_smi)
    
    # 原子数检查
    if child_mol.GetNumAtoms() > parent_mol.GetNumAtoms():
        return False
    
    # *数量检查
    parent_dummy = count_dummy(parent_mol)
    child_dummy = count_dummy(child_mol)
    if child_dummy < parent_dummy:
        return False
    
    # 子结构匹配
    if child_mol.HasSubstructMatch(parent_mol):
        return True
    
    return False
```

**示例**:
```
Parent: *c1ccc(S(*)(=O)=O)cc1C
可能的Children:
✓ *NS(=O)(=O)c1ccc(*)c(C)c1  (替换了苯环部分)
✓ *c1ccc(S(=O)(=O)N*)cc1C    (替换了磺酰胺上的R基)
✗ *c1ccccc1                 (完全不同的结构)
```

---

### 3. real_sonNode() 直接子节点判定

**问题**: 
- A是B的父节点，B是C的父节点
- 但A不能直接指向C（避免跳层）

**解决方案**:
```python
def real_sonNode(child_smi, all_children_smis, parent_dict):
    """
    判定child是否为当前节点的直接子节点
    
    逻辑:
    1. child必须在all_children_smis中（是子节点）
    2. child的父节点中，不能有其他在all_children_smis中的节点
       （如果有，说明中间还有一层，child不是直接子节点）
    """
    
    child_parents = parent_dict[child_smi]
    
    for other_child in all_children_smis:
        if other_child == child_smi:
            continue
        
        # 如果other_child是child的父节点
        if other_child in child_parents:
            # child不是直接子节点
            return False
    
    return True
```

**示例**:
```
当前节点: A
所有子节点: [B, C, D]

检查C是否为A的直接子节点:
- C的父节点: [A, B]
- B也在子节点列表中
- 说明: A → B → C (B是中间节点)
- 结论: C不是A的直接子节点

正确的树结构:
A
├── B
│   └── C
└── D
```

---

### 4. 高亮显示算法

#### 匹配片段到化合物
```python
def match_fragment_to_compounds(fragment_smi, df_act):
    """
    找出包含指定片段的所有化合物
    
    步骤:
    1. 将fragment作为SMARTS模式
    2. 遍历df_act中的所有化合物
    3. 使用子结构匹配
    """
    
    frag_mol = Chem.MolFromSmarts(fragment_smi)
    matched_compounds = []
    
    for idx, row in df_act.iterrows():
        cpd_mol = Chem.MolFromSmiles(row['Cano_SMILES'])
        
        if cpd_mol.HasSubstructMatch(frag_mol):
            matched_compounds.append(row)
    
    return pd.DataFrame(matched_compounds)
```

#### 计算统计值并判定
```python
def should_highlight(matched_cpds, highlight_dict):
    """
    根据highlightDict判定是否高亮
    
    highlightDict示例:
    {
        'col': 'IC50_uM',
        'type': 'mean',
        'relation': '<',
        'value': 1.0
    }
    """
    
    col = highlight_dict['col']
    stat_type = highlight_dict['type']
    relation = highlight_dict['relation']
    threshold = highlight_dict['value']
    
    # 计算统计值
    if stat_type == 'mean':
        stat_value = matched_cpds[col].mean()
    elif stat_type == 'median':
        stat_value = matched_cpds[col].median()
    elif stat_type == 'std':
        stat_value = matched_cpds[col].std()
    
    # 判定
    if relation == '<':
        return stat_value < threshold
    elif relation == '>':
        return stat_value > threshold
    elif relation == '=':
        return abs(stat_value - threshold) < 0.01
    
    return False
```

**应用场景**:
```
highlightDict = [
    {'col':'IC50_uM', 'type':'mean', 'relation':'<', 'value':1.0},
    {'col':'Selectivity', 'type':'median', 'relation':'>', 'value':10}
]

意义:
- 高亮平均IC50 < 1.0 µM (高活性)
- 且中位数选择性 > 10倍 (高选择性)
```

---

## 工具函数说明

### 1. SMILES处理函数

#### canonic_smiles()
```python
def canonic_smiles(smi):
    """
    将SMILES标准化
    
    功能:
    - 消除同分异构体的不同写法
    - 统一表示形式
    
    示例:
    C(C)O  →  CCO
    c1ccccc1  →  c1ccccc1  (保持芳香性)
    """
    mol = Chem.MolFromSmiles(smi)
    if mol is None:
        return None
    return Chem.MolToSmiles(mol)
```

#### remove_dummy()
```python
def remove_dummy(smi):
    """
    移除SMILES中的占位符(*)
    
    示例:
    *c1ccccc1  →  c1ccccc1
    *NS(=O)(=O)*  →  NS(=O)=O
    """
    return smi.replace('*', '')
```

---

### 2. 数据验证函数

#### df_valid()
```python
def df_valid(df, row_smi='smiles'):
    """
    验证DataFrame中SMILES的有效性
    
    步骤:
    1. 尝试解析每个SMILES
    2. 过滤掉无法解析的行
    3. 返回有效数据
    """
    def is_valid_smiles(smi):
        mol = Chem.MolFromSmiles(smi)
        return mol is not None
    
    df['valid'] = df[row_smi].apply(is_valid_smiles)
    return df[df['valid']].drop('valid', axis=1)
```

#### float_row()
```python
def float_row(df, cols, dropna=True):
    """
    将指定列转换为浮点数
    
    功能:
    - 处理字符串数值
    - 清理非数值数据
    - 可选删除NaN
    """
    for col in cols:
        df[col] = pd.to_numeric(df[col], errors='coerce')
    
    if dropna:
        df = df.dropna(subset=cols)
    
    return df
```

---

### 3. 并行处理

#### pandarallel使用
```python
from pandarallel import pandarallel

n_jobs = 30
pandarallel.initialize(nb_workers=n_jobs)

# 使用parallel_apply代替apply
df['result'] = df['column'].parallel_apply(function)
```

**优势**:
- 自动并行化数据处理
- 显示进度条
- 充分利用多核CPU

**适用场景**:
- SMILES标准化（计算密集）
- 片段匹配（大量子结构搜索）
- 分子属性计算

---

### 4. 文件输出函数

#### csvToExcel()
```python
def csvToExcel(csv_file):
    """
    将CSV转换为Excel格式
    
    优势:
    - Excel支持多个Sheet
    - 更好的格式化
    - 方便人工查看
    """
    df = pd.read_csv(csv_file)
    excel_file = csv_file.replace('.csv', '.xlsx')
    df.to_excel(excel_file, index=False)
```

---

## 使用示例

### 示例1: 创建SAR表

```bash
python create_sarm.py \
  --csvFile ./data/compounds.csv \
  --column IC50_uM Selectivity \
  --type smiles \
  --log 0 \
  --minimumSite1 3 \
  --minimumSite2 3 \
  --n_jobs 30 \
  --save_folder ./SAR_Results/SAR_Tables \
  --csv2excel 1
```

**参数解释**:
- `csvFile`: 输入CSV，必须包含smiles列
- `column`: 要分析的活性列（可多个）
- `type`: smiles（完整分子）或scaffold（仅骨架）
- `log`: 是否对活性值取对数（0=否，1=是）
- `minimumSite1/2`: 最小片段频次（过滤稀有片段）
- `n_jobs`: 并行核心数
- `save_folder`: 输出目录
- `csv2excel`: 是否同时生成Excel文件

---

### 示例2: 生成SAR树

```bash
python create_tree.py \
  --fragment_core "*c1ccc(S(*)(=O)=O)cc1C" \
  --rootTitle "Table_100_combine" \
  --workFolder ./SAR_Results \
  --maxLevel 5 \
  --treeContent "['double-cut']" \
  --highlightDict "[{'col':'IC50_uM', 'type':'mean', 'relation':'<', 'value':1.0}]"
```

**参数解释**:
- `fragment_core`: 要分析的核心片段（必须带*占位符）
- `rootTitle`: 对应SAR表中的表名
- `workFolder`: SAR_Tables所在目录
- `maxLevel`: 树的最大深度（5表示最多5层）
- `treeContent`: 包含的内容类型
  - `double-cut`: 二次切割片段
  - `single-cut`: 单次切割片段
  - `whole-compound`: 完整化合物
- `highlightDict`: 高亮条件
  - `col`: 列名
  - `type`: 统计类型（mean/median/std）
  - `relation`: 比较关系（</>/=）
  - `value`: 阈值

---

### 示例3: 多条件高亮

```bash
--highlightDict "[
  {'col':'IC50_uM', 'type':'mean', 'relation':'<', 'value':1.0},
  {'col':'Selectivity', 'type':'median', 'relation':'>', 'value':10}
]"
```

**含义**:
- 同时满足两个条件才高亮
- 条件1: 平均IC50 < 1.0 µM（高活性）
- 条件2: 中位数选择性 > 10倍（高选择性）

---

## 常见问题与解决方案

### 问题1: KeyError: 'Key2'

**原因**: CSV文件列名不一致

**解决**: create_tree.py已添加兼容性代码
```python
if "Key2" in df_tmp.columns:
    df_tmp["SMILES"] = df_tmp["Key2"]
elif "SMILES" not in df_tmp.columns:
    raise ValueError("Must have 'Key2' or 'SMILES' column")
```

---

### 问题2: 字体大小警告

**现象**:
```
The new font size 640 is above the current maximum (40).
```

**影响**: 不影响功能，仅为警告

**解决**（可选）:
```python
# 在create_tree.py中调整字体大小
d.node_attr.update(fontsize='14')  # 降低字体大小
```

---

### 问题3: Empty DataFrame

**现象**: 某些片段显示"Empty DataFrame"

**原因**: 
- input.csv中没有包含该片段的化合物
- 属于正常情况（不是所有片段都有实际化合物）

**处理**: 
- 不影响其他节点
- 这些节点不会显示活性信息

---

### 问题4: 内存不足

**症状**: 处理大数据集时程序崩溃

**解决方案**:
1. 减少并行核心数
```bash
--n_jobs 8  # 从30降低到8
```

2. 分批处理
```python
# 将数据分成多个小文件处理
df_chunks = np.array_split(df, 10)
for chunk in df_chunks:
    process_chunk(chunk)
```

3. 增加minimum_count
```bash
--minimumSite1 5  # 从3增加到5，减少片段数量
```

---

## 总结

### create_sarm.py 核心功能
1. **输入**: 化合物SMILES + 活性值
2. **处理**: 分子切割 → 片段统计 → SAR表生成
3. **输出**: 左/右/组合SAR表

### create_tree.py 核心功能
1. **输入**: SAR表 + 核心片段 + 高亮条件
2. **处理**: 树构建 → 活性关联 → 可视化
3. **输出**: PDF树图 + PNG节点图

### 关键创新点
1. **自动化片段化**: 无需人工定义R基团
2. **层次化展示**: 树状图直观显示SAR关系
3. **活性高亮**: 自动突出高活性化合物
4. **并行加速**: 利用多核处理大数据集

### 应用价值
- **药物设计**: 快速识别活性热点
- **先导优化**: 指导R基团选择
- **SAR分析**: 可视化结构-活性关系
- **化学空间探索**: 发现未合成的潜在化合物

---

**文档维护**: GitHub Copilot  
**最后更新**: 2025年11月23日  
**版本**: 1.0
